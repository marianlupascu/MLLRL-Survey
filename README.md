# Multimodal Learning for Low-Resource Languages: A Survey

This repository contains a curated collection of research papers focusing on multimodal approaches for low-resource languages. The collection spans from 2018 to 2024, showcasing the evolution and advancement of techniques in this field.

## Overview

The papers in this collection cover various aspects of multimodal approaches for low-resource languages, including:
- Visual enhancement techniques
- Data creation and engineering
- Fusion techniques
- Cross-modal transfer
- Synthetic data generation
- Architecture innovations


## Language Coverage

The collection includes papers covering 26 languages:
- Hindi (12 papers)
- Chinese/Mandarin (7 papers)
- Bengali, Arabic, Malayalam (6 papers each)
- Amharic, Tamil (5 papers each)
- Urdu, Vietnamese, Assamese, Hausa (3 papers each)
- Mongolian, Yoruba (2 papers each)
- Romanian, Fongbe, Bemba, Persian, Igbo, Azerbaijani, Tagalog, Kazakh, Manipuri, Lao, Sinhala, Javanese, Uyghur (1 paper each)

## Categories

### Visual Enhancement Techniques
Papers focusing on improving translation and understanding through visual information:
| No | Title | Year | Link |
|----|-------|------|------|
| 1 | Multimodal Neural Machine Translation for Low-resource Language Pairs using Synthetic Data | 2018 | [Link](https://aclanthology.org/W18-3405/) |
| 2 | Multimodal Neural Machine Translation for English to Hindi | 2020 | [Link](https://aclanthology.org/2020.wat-1.11/) |
| 3 | Multimodal Neural Machine Translation for Englishâ€“Assamese Pair | 2021 | [Link](https://ieeexplore.ieee.org/abstract/document/9752181) |
| 4 | Multimodal neural machine translation system for English to Bengali | 2021 | [Link](https://aclanthology.org/2021.mmtlrl-1.6.pdf) |
| 5 | MURAL: Multimodal, Multitask Retrieval Across Languages | 2021 | [Link](https://arxiv.org/pdf/2109.05125) |
| 6 | Investigation of English to Hindi Multimodal Neural Machine Translation using Transliteration-based Phrase Pairs Augmentation | 2022 | [Link](https://aclanthology.org/2022.wat-1.15/) |
| 7 | Adding Visual Information to Improve Multimodal Machine Translation for Low-Resource Language | 2022 | [Link](https://onlinelibrary.wiley.com/doi/epdf/10.1155/2022/5483535) |
| 8 | English -Malayalam Vision aid with Multi Modal Machine Learning Technologies | 2022 | [Link](https://ieeexplore.ieee.org/abstract/document/9788187?casa_token=RNYhqj4fgxAAAAAA:uQL7UrSFXSqY9dYNrkEj60r_kin0LvVQ0c3rx1grl-533rIducnNN2npSXwjLcOX5ZRhd_CV) |
| 9 | Multimodal Neural Machine Translation for Mongolian to Chinese | 2022 | [Link](https://ieeexplore.ieee.org/document/9892831?denied=) |
| 10 | Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages | 2023 | [Link](https://arxiv.org/abs/2308.16075) |
| 11 | Do cues in a video help in handling rare words in a machine translation system under a low-resource setting? | 2023 | [Link](https://www.sciencedirect.com/science/article/pii/S2949719123000134) |
| 12 | Hindi to English Multimodal Machine Translation on News Dataset in Low Resource Setting | 2023 | [Link](https://www.sciencedirect.com/science/article/pii/S1877050923001862) |
| 13 | DCU ADAPT at WMT24: English to Low-resource Multi-Modal Translation Task | 2024 | [Link](https://aclanthology.org/2024.wmt-1.75/) |
| 14 | An analysis of minimal pairs in Igbo using a multimodal approach to speech perception | 2024 | [Link](https://www.ajol.info/index.php/ujah/article/view/272304) |
| 15 | Multimodal Attention-Driven Visual Question Answering for Malayalam | 2024 | [Link](https://www.researchgate.net/profile/Sikha-O-K/publication/380486380_Multimodal_attention-driven_visual_question_answering_for_Malayalam/links/66438ec008aa54017a0905fc/Multimodal-attention-driven-visual-question-answering-for-Malayalam.pdf) |
| 16 | Unsupervised Multimodal Machine Translation for Low-resource Distant Language Pairs | 2024 | [Link](https://dl.acm.org/doi/10.1145/3652161) |
| 17 | Low-Resource Machine Translation with Different Granularity Image Features | 2024 | [Link](https://link.springer.com/chapter/10.1007/978-981-97-8620-6_18) |

### Data Creation & Engineering  
Papers on dataset creation and curation:  
| No | Title | Year | Link |  
|----|-------|------|------|  
| 1  | Multimodal Sentiment Analysis of Arabic Videos | 2018 | [Link](https://www.joig.net/uploadfile/2018/0717/20180717061609554.pdf) |  
| 2  | Hindi Visual Genome: A Dataset for Multimodal English-to-Hindi Machine Translation | 2019 | [Link](https://arxiv.org/abs/1907.08948) |  
| 3  | Improved English to Hindi Multimodal Neural Machine Translation | 2021 | [Link](https://aclanthology.org/2021.wat-1.17/) |  
| 4  | Experiences of Adapting Multimodal Machine Translation Techniques for Hindi | 2021 | [Link](https://aclanthology.org/2021.mmtlrl-1.7/) |  
| 5  | An experiment on speech-to-text translation systems for Manipuri to English on low resource setting | 2021 | [Link](https://aclanthology.org/2021.icon-main.8/) |  
| 6  | LaoPLM: Pre-trained Language Models for Lao | 2021 | [Link](https://arxiv.org/abs/2110.05896) |  
| 7  | Hausa visual genome: A dataset for multi-modal English to Hausa machine translation | 2022 | [Link](https://arxiv.org/abs/2205.01133) |  
| 8  | Bengali Visual Genome: A Multimodal Dataset for Machine Translation and Image Captioning | 2022 | [Link](https://ufal.mff.cuni.cz/biblio/attachments/2022-bojar-m2165457966160174801.pdf) |  
| 9  | Mute: A multimodal dataset for detecting hateful memes | 2022 | [Link](https://aclanthology.org/2022.aacl-srw.5/) |  
| 10 | MemoSen: A Multimodal Dataset for Sentiment Analysis of Memes | 2022 | [Link](https://aclanthology.org/2022.lrec-1.165/) |  
| 11 | [RETRACTED] Uzbek for My Heart: Language Choice and Identity Negotiation in Multilingual Uzbekistan | 2022 | [Link](https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/8220998) |  
| 12 | English-Assamese Multimodal Neural Machine Translation using Transliteration-based Phrase Augmentation Approach | 2023 | [Link](https://www.sciencedirect.com/science/article/pii/S1877050923000789) |  
| 13 | Towards Arabic Multimodal Dataset for Sentiment Analysis | 2023 | [Link](https://ieeexplore.ieee.org/abstract/document/10317847) |  
| 14 | BIG-C: a Multimodal Multi-Purpose Dataset for Bemba | 2023 | [Link](https://arxiv.org/abs/2305.17202) |  
| 15 | ArabSign: A Multi-modality Dataset and Benchmark for Continuous Arabic Sign Language Recognition | 2023 | [Link](https://arxiv.org/pdf/2210.03951) |  
| 16 | Extension Multi30K: Multimodal Dataset for Integrated Vision and Language Research in Ukrainian | 2023 | [Link](https://aclanthology.org/2023.unlp-1.7/) |  
| 17 | MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition and Robust Speech-to-Text Translation | 2023 | [Link](https://www.isca-archive.org/interspeech_2023/anwar23_interspeech.pdf) |  
| 18 | HaVQA: A Dataset for Visual Question Answering and Multimodal Research in Hausa Language | 2023 | [Link](https://arxiv.org/abs/2305.17690) |  
| 19 | Explainable Multimodal Sentiment Analysis on Bengali Memes | 2023 | [Link](https://arxiv.org/abs/2401.09446) |  
| 20 | Multimodal Sentiment Analysis for the Malay Language: New Corpus using CNN-based Framework | 2024 | [Link](https://dl.acm.org/doi/abs/10.1145/3703445) |  
| 21 | Dravidianmultimodality: A dataset for multi-modal sentiment analysis in Tamil and Malayalam | 2024 | [Link](https://arxiv.org/pdf/2106.04853) |  
| 22 | SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages | 2024 | [Link](https://arxiv.org/pdf/2406.10118) |  
| 23 | RoMemes: A multimodal meme corpus for the Romanian language | 2024 | [Link](https://arxiv.org/abs/2410.15497) |  
| 24 | An empirical study of a novel multimodal dataset for low-resource machine translation | 2024 | [Link](https://dl.acm.org/doi/abs/10.1007/s10115-024-02087-6) |  
| 25 | FFSTC: Fongbe to French Speech Translation Corpus | 2024 | [Link](https://arxiv.org/pdf/2403.05488) |  
| 26 | A scarce dataset for ancient Arabic handwritten text recognition | 2024 | [Link](https://pubmed.ncbi.nlm.nih.gov/39252777/) |  
| 27 | Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings | 2024 | [Link](https://arxiv.org/pdf/2409.06013) |  
| 28 | CreoleVal: Multilingual Multitask Benchmarks for Creoles | 2024 | [Link](https://arxiv.org/html/2310.19567v3) |  
| 29 | Towards a Multimodal WordNet for Language Learning in Bulgarian | 2024 | [Link](https://dipp.math.bas.bg/dipp/article/view/dipp.2024.14.10) |  

### Fusion Techniques
Papers exploring different methods of combining multimodal information:
| No | Title | Year | Link |
| --------| -------- | ------- | ------- |
| 1 | Multilingual Multimodal Machine Translation for Dravidian Languages utilizing Phonetic Transcription | 2019 | [Link](https://aclanthology.org/W19-6809/) |
| 2 | Enhanced Video Analytics for Sentiment Analysis Based on Fusing Textual, Auditory and Visual Information (Arabic languages) | 2020 | [Link](https://ieeexplore.ieee.org/abstract/document/9148603) |
| 3 | A novel context-aware multimodal framework for Persian sentiment analysis | 2021 | [Link](https://arxiv.org/pdf/2103.02636) |
| 4 | Arabic language investigation in the context of unimodal and multimodal sentiment analysis | 2021 | [Link](https://ieeexplore.ieee.org/document/9677274) |
| 5 | Urdu sentiment analysis via multimodal data mining based on deep learning algorithms | 2021 | [Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583225) |
| 6 | A multi-stage multimodal framework for sentiment analysis of Assamese in low resource setting | 2022 | [Link](https://www.sciencedirect.com/science/article/abs/pii/S0957417422008879) |
| 7 | An Efficient Fusion Mechanism for Multimodal Low-resource Setting | 2022 | [Link](https://www.cse.iitb.ac.in/~pb/papers/sigir22-fusion.pdf) |
| 8 | Multimodal Amharic hate speech detection using deep learning | 2022 | [Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9971436&casa_token=xeBIN0VTl5QAAAAA:GZ4SROECxtcYC81_au4llawYOp8TXvSJtREQWsutPi65VirsDLCL7KJY9TY0ikhQXaZp0m82&tag=1) |
| 9 | Multimodal Hate Speech Detection from Bengali Memes and Texts | 2022 | [Link](https://arxiv.org/pdf/2204.10196) |
| 10 | Multimodal hate speech detection from Bengali memes and texts | 2022 | [Link](https://link.springer.com/chapter/10.1007/978-3-031-33231-9_21) |
| 11 | A Novel Deep Learning Multi-Modal Sentiment Analysis Model for English and Egyptian Arabic Dialects Using Audio and Text | 2023 | [Link](https://ieeexplore.ieee.org/document/10453875) |
| 12 | Exploiting multiple correlated modalities can enhance low-resource machine translation quality | 2023 | [Link](https://link.springer.com/article/10.1007/s11042-023-15721-2) |
| 13 | Findings of the Shared Task on Multimodal Abusive Language Detection and Sentiment Analysis in Tamil and Malayalam | 2023 | [Link](https://aclanthology.org/2023.dravidianlangtech-1.10.pdf) |
| 14 | Multi-modal Hate Speech Detection for Amharic using Deep Learning | 2023 | [Link](https://www.researchgate.net/profile/Michael-Woldeyohannis/publication/366127526_Multimodal_Amharic_Hate_Speech_Detection_Using_Deep_Learning/links/639b40a7e42faa7e75c57cfc/Multimodal-Amharic-Hate-Speech-Detection-Using-Deep-Learning.pdf) |
| 15 | Multimodal Arabic emotion recognition using deep learning | 2023 | [Link](https://dl.acm.org/doi/10.1016/j.specom.2023.103005) |
| 16 | Multimodal Arabic Rumors Detection | 2023 | [Link](https://ieeexplore.ieee.org/abstract/document/10026837) |
| 17 | SADTech@DravidianLangTech: Multimodal Sentiment Analysis of Tamil and Malayalam | 2023 | [Link](https://aclanthology.org/2023.dravidianlangtech-1.37/) |
| 18 | English-to-low-resource translation: A multimodal approach for Hindi, Malayalam, Bengali, and Hausa | 2024 | [Link](https://aclanthology.org/2024.wmt-1.76/) |
| 19 | A Lip-Reading Model for Tagalog Using Multimodal Deep Learning Approach | 2024 | [Link](https://stepacademic.net/ijcsr/article/view/511) |
| 20 | Advanced Multimodal Emotion Recognition for Javanese Language Using Deep Learning | 2024 | [Link](https://section.iaesonline.com/index.php/IJEEI/article/viewFile/5662/928) |
| 21 | Detecting Hate Speech in Amharic Using Multimodal Analysis of Social Media Memes | 2024 | [Link](https://aclanthology.org/2024.trac-1.10.pdf) |
| 22 | Multi-modal Deep Learning Approach to Improve Sentence level Sinhala Sign Language Recognition | 2024 | [Link](https://journal.icter.org/index.php/ICTer/article/view/494) |
| 23 | Multi-modal Sentiment Analysis of Mongolian Language based on Pre-trained Models and High-resolution Networks | 2024 | [Link](https://ieeexplore.ieee.org/document/10661161?denied=) |
| 24 | Multimodal Abusive Language Detection in Tamil based on Integrated Approach of Machine Learning and Deep Learning Techniques | 2024 | [Link](https://aclanthology.org/2024.dravidianlangtech-1.35.pdf) |
| 25 | Multi-level Contrastive Learning: Hierarchical Alleviation of Heterogeneity in Multimodal Sentiment Analysis | 2024 | [Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10587106&casa_token=374cnGfCob0AAAAA:aktq2dMEsQxDxwnF5SWyIEftX4k_112P6XrwXj0xbbG-RN7tpPsdfuRxsijCVwS9fiyjT9hE&tag=1) |
| 26 | Multimodal Sensing for Depression Risk Detection: Integrating Audio, Video, and Text Data | 2024 | [Link](https://www.mdpi.com/1424-8220/24/12/3714) |
| 27 | Multimodal systems for speech recognition | 2024 | [Link](https://www.researchgate.net/profile/Mamyrbayev-Orken/publication/364253520_MULTIMODAL_SYSTEMS_FOR_SPEECH_RECOGNITION/links/6344d6afff870c55ce166c8c/MULTIMODAL-SYSTEMS-FOR-SPEECH-RECOGNITION.pdf) |


### Cross-Modal Transfer
Papers on transferring knowledge between modalities:
| No | Title | Year | Link |
|----|-------|------|------|
| 1 | When Pairs Meet Triplets: Improving Low-Resource Captioning via Multi-Objective Optimization | 2022 | [Link](https://dl.acm.org/doi/abs/10.1145/3492325) |
| 2 | A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation | 2022 | [Link](https://arxiv.org/pdf/2203.04287) |
| 3 | A Multimodal Approach for Real-Time Sinhala Sign Language Translation | 2023 | [Link](https://irjiet.com/Volume-7/Issue-10-October-2023/A-Multimodal-Approach-for-Real-Time-Sinhala-Sign-Language-Translation/1837) |
| 4 | Adapting Grounded Visual Question Answering Models to Low Resource Languages | 2023 | [Link](https://openaccess.thecvf.com/content/CVPR2023W/MULA/papers/Wang_Adapting_Grounded_Visual_Question_Answering_Models_to_Low_Resource_Languages_CVPRW_2023_paper.pdf) |
| 5 | CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages | 2023 | [Link](https://arxiv.org/abs/2310.13683) |
| 6 | Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge | 2023 | [Link](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.html) |
| 7 | A multilingual training strategy for low resource Text to Speech | 2024 | [Link](https://arxiv.org/html/2409.01217v1) |
| 8 | Adapting multilingual vision language transformers for low-resource Urdu optical character recognition (OCR) | 2024 | [Link](https://peerj.com/articles/cs-1964/) |
| 9 | Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages | 2024 | [Link](https://arxiv.org/pdf/2403.06354) |
| 10 | LaVy: Vietnamese Multimodal Large Language Model | 2024 | [Link](https://arxiv.org/abs/2404.07922) |
| 11 | LLMs for Low Resource Languages in Multilingual, Multimodal and Dialectal Settings | 2024 | [Link](https://aclanthology.org/2024.eacl-tutorials.5/) |
| 12 | Multimodal Cross-Modal Transfer Learning for Low-Resource Language Processing: A Framework for Leveraging Speech Data | 2024 | [Link](https://www.researchgate.net/publication/383948435_Multimodal_Cross-Modal_Transfer_Learning_for_Low-Resource_Language_Processing_A_Framework_for_Leveraging_Speech_Data) |
| 13 | Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks | 2024 | [Link](https://arxiv.org/abs/2403.01031) |
| 14 | Qalam: A Multimodal LLM for Arabic Optical Character and Handwriting Recognition | 2024 | [Link](https://arxiv.org/abs/2407.13559) |
| 15 | Sentiment analysis on a low-resource language dataset using multimodal representation learning and cross-lingual transfer learning | 2024 | [Link](https://www.sciencedirect.com/science/article/abs/pii/S1568494624003272) |
| 16 | The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts | 2024 | [Link](https://arxiv.org/abs/2401.13136v1) |
| 17 | Visual Speech Recognition for Languages with Limited Labeled Data using Automatic Labels from Whisper | 2024 | [Link](https://arxiv.org/abs/2309.08535) |
| 18 | Visually Grounded Few-Shot Word Learning in Low-Resource Settings | 2024 | [Link](https://arxiv.org/abs/2306.11371) |
| 19 | Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets | 2024 | [Link](https://arxiv.org/abs/2402.08015) |


### Synthetic Data Generation
Papers exploring methods to create artificial training data:
| No | Title | Year | Link |
| --------| -------- | ------- | ------- |
| 1 | Low Resource Multimodal Neural Machine Translation of English-Hindi in News Domain | 2021 | [Link](https://aclanthology.org/2021.mmtlrl-1.4/) |
| 2 | Cross-Lingual Cross-Modal Retrieval with Noise-Robust Learning | 2022 | [Link](https://arxiv.org/pdf/2208.12526) |
| 3 | Image Caption Generation for Low-Resource Assamese Language | 2022 | [Link](https://aclanthology.org/2022.rocling-1.33.pdf) |
| 4 | BITS-P at WAT 2023: Improving Indic Language Multimodal Translation by Image Augmentation using Diffusion Models | 2023 | [Link](https://aclanthology.org/2023.wat-1.3/)              |
| 5 | Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic | 2024 | [Link](https://arxiv.org/abs/2407.18129) |
| 6 | Multimodal Seed Data Augmentation for Low-Resource Audio Latin Cuengh Language | 2024 | [Link](https://www.researchsquare.com/article/rs-4734892/v1)|
| 7 | ELAICHI: Enhancing Low-Resource TTS by Addressing Infrequent and Low-Frequency Character Bigrams| 2024 | [Link](https://arxiv.org/abs/2410.17901) |
| 8 | Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese | 2024 | [Link](https://arxiv.org/pdf/2408.12480) |
| 9 | Mitigating Multilingual Hallucination in Large Vision-Language Models | 2024 | [Link](https://arxiv.org/pdf/2408.00550) |


### Architecture Innovations
Papers introducing novel model architectures and approaches:
| No | Title | Year | Link |
|----|-------|------|------|
| 1 | Improving Captioning for Low-Resource Languages by Cycle Consistency | 2019 | [Link](https://arxiv.org/pdf/1908.07810) |
| 2 | Exploring Multi-lingual, Multi-task, and Adversarial Learning for Low-resource Sentiment Analysis | 2022 | [Link](https://dl.acm.org/doi/abs/10.1145/3514498) |
| 3 | A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models | 2022 | [Link](https://arxiv.org/abs/2110.08484) |
| 4 | Amharic Language Image Captions Generation Using Hybridized Attention-Based Deep Neural Networks | 2023 | [Link](https://onlinelibrary.wiley.com/doi/10.1155/2023/9397325) |
| 5 | Improving Massively Multilingual ASR With Auxiliary CTC Objectives | 2023 | [Link](https://arxiv.org/pdf/2302.12829) |
| 6 | Morphology & word sense disambiguation embedded multimodal neural machine translation system between Sanskrit and Malayalam | 2023 | [Link](https://www.sciencedirect.com/science/article/abs/pii/S1746809423004846) |
| 7 | Self-PT: Adaptive Self-Prompt Tuning for Low-Resource Visual Question Answering | 2023 | [Link](https://dl.acm.org/doi/abs/10.1145/3581783.3612222) |
| 8 | XtremeCLIP: Extremely Parameter-efficient Tuning for Low-resource Vision Language Understanding | 2023 | [Link](https://aclanthology.org/2023.findings-acl.397/) |
| 9 | LowCLIP: Adapting the CLIP Model Architecture for Low-Resource Languages in Multimodal Image Retrieval Task | 2024 | [Link](https://arxiv.org/abs/2408.13909) |
| 10 | Speech Recognition Model in Yoruba Language | 2024 | [Link](https://researchvision.us/index.php/smartify/article/view/5) |


## Citation

TODO

## Contributing

We welcome contributions to this collection. Please submit a pull request with:
- The paper's PDF (if openly available)
- Updated BibTeX entry
- Brief description of the paper's key contributions
- Categorization according to our existing schema

## License

This collection is for research purposes only. All papers remain under their original licenses and copyright holders.

## Contact

For questions or suggestions about this collection, please open an issue in this repository.

# Multimodal Learning for Low-Resource Languages: A Survey

This repository contains a curated collection of research papers focusing on multimodal approaches for low-resource languages. The collection spans from 2018 to 2024, showcasing the evolution and advancement of techniques in this field.

## Overview

The papers in this collection cover various aspects of multimodal approaches for low-resource languages, including:
- Visual enhancement techniques
- Data creation and engineering
- Fusion techniques
- Cross-modal transfer
- Synthetic data generation
- Architecture innovations


## Language Coverage

The collection includes papers covering 26 languages:
- Hindi (12 papers)
- Chinese/Mandarin (7 papers)
- Bengali, Arabic, Malayalam (6 papers each)
- Amharic, Tamil (5 papers each)
- Urdu, Vietnamese, Assamese, Hausa (3 papers each)
- Mongolian, Yoruba (2 papers each)
- Romanian, Fongbe, Bemba, Persian, Igbo, Azerbaijani, Tagalog, Kazakh, Manipuri, Lao, Sinhala, Javanese, Uyghur (1 paper each)

## Categories

### Visual Enhancement Techniques
Papers focusing on improving translation and understanding through visual information:
- ["Multimodal Neural Machine Translation for Low-resource Language Pairs using Synthetic Data" (2018)](https://doras.dcu.ie/23355/1/Multimodal_Neural_Machine_Translation_for_low-resource_language_pairs_using_synthetic_data%5B1%5D.pdf)
- ["Multimodal Neural Machine Translation for English to Hindi" (2020)](https://aclanthology.org/2020.wat-1.11.pdf)
- ["MURAL: Multimodal, Multitask Retrieval Across Languages" (2021)](https://arxiv.org/pdf/2109.05125)
- ["Adding Visual Information to Improve Multimodal Machine Translation for Low-Resource Language" (2022)](https://onlinelibrary.wiley.com/doi/pdf/10.1155/2022/5483535)
- ["Do cues in a video help in handling rare words in a machine translation system under a low-resource setting?" (2023)](https://www.sciencedirect.com/science/article/pii/S2949719123000134)
- ["DCU ADAPT at WMT24: English to Low-resource Multi-Modal Translation Task" (2024)](https://aclanthology.org/2024.wmt-1.75.pdf)
- ["English -Malayalam Vision aid with Multi Modal Machine Learning Technologies" (2022)](https://ieeexplore.ieee.org/document/9788187)

### Data Creation & Engineering
Papers on dataset creation and curation:
- ["Multimodal Sentiment Analysis of Arabic Videos" (2018)](https://www.joig.net/uploadfile/2018/0717/20180717061609554.pdf)
- ["Hindi Visual Genome: A Dataset for Multimodal English-to-Hindi Machine Translation" (2019)](https://www.scielo.org.mx/scielo.php?pid=S1405-55462019000401499&script=sci_arttext&tlng=en)
- ["Bengali Visual Genome: A Multimodal Dataset for Machine Translation and Image Captioning" (2022)](https://ufal.mff.cuni.cz/biblio/attachments/2022-bojar-m2165457966160174801.pdf)
- ["Hausa visual genome: A dataset for multi-modal English to Hausa machine translation" (2022)](https://arxiv.org/pdf/2205.01133)
- ["MemoSen: A Multimodal Dataset for Sentiment Analysis of Memes" (2022)](https://aclanthology.org/2022.lrec-1.165.pdf)
- ["Mute: A multimodal dataset for detecting hateful memes" (2022)](https://aclanthology.org/2022.aacl-srw.5.pdf)
- ["ArabSign: A Multi-modality Dataset and Benchmark for Continuous Arabic Sign Language Recognition" (2023)](https://ieeexplore.ieee.org/document/10042720)
- ["BIG-C: a Multimodal Multi-Purpose Dataset for Bemba" (2023)](https://arxiv.org/pdf/2305.17202)
- ["Extension Multi30K: Multimodal Dataset for Integrated Vision and Language Research in Ukrainian" (2023)](https://aclanthology.org/2023.unlp-1.7.pdf)
- ["Towards Arabic Multimodal Dataset for Sentiment Analysis" (2023)](https://ieeexplore.ieee.org/document/10317847)
- ["RoMemes: A multimodal meme corpus for the Romanian language" (2024)](https://arxiv.org/pdf/2410.15497)
- ["SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages" (2024)](https://arxiv.org/pdf/2406.10118)
- ["FFSTC: Fongbe to French Speech Translation Corpus" (2024)](https://arxiv.org/pdf/2403.05488)

### Fusion Techniques
Papers exploring different methods of combining multimodal information:
- "Multilingual Multimodal Machine Translation for Dravidian Languages utilizing Phonetic Transcription" (2019)
- "Enhanced Video Analytics for Sentiment Analysis Based on Fusing Textual, Auditory and Visual Information" (2020)
- "A novel context-aware multimodal framework for persian sentiment analysis" (2021)
- "Urdu sentiment analysis via multimodal data mining based on deep learning algorithms" (2021)
- "An Efficient Fusion Mechanism for Multimodal Low-resource Setting" (2022)
- "SADTech@DravidianLangTech: Multimodal Sentiment Analysis of Tamil and Malayalam" (2023)
- "Multimodal Arabic Rumors Detection" (2023)
- "Exploiting multiple correlated modalities can enhance low-resource machine translation quality" (2023)
- "Multi-modal Deep Learning Approach to Improve Sentence level Sinhala Sign Language Translation" (2024)
- "Multi-modal Sentiment Analysis of Mongolian Language based on Pre-trained Models and High-resolution Networks" (2024)
- "Multi-level Contrastive Learning: Hierarchical Alleviation of Heterogeneity in Multimodal Sentiment Analysis" (2024)
- "CUET-NLP@ DravidianLangTech" (2024)
- "Advanced Multimodal Emotion Recognition for Javanese Language Using Deep Learning" (2024)

### Cross-Modal Transfer
Papers on transferring knowledge between modalities:
- "Improving Captioning for Low-Resource Languages by Cycle Consistency" (2019)
- "When Pairs Meet Triplets: Improving Low-Resource Captioning via Multi-Objective Optimization" (2022)
- "MURAL: Multimodal, Multitask Retrieval Across Languages" (2021)
- "CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages" (2023)
- "Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge" (2023)
- "Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages" (2024)
- "LaVy: Vietnamese Multimodal Large Language Model" (2024)
- "Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks" (2024)
- "Qalam: A Multimodal LLM for Arabic Optical Character and Handwriting Recognition" (2024)
- "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets" (2024)
- "Visual Speech Recognition for Languages with Limited Labeled Data using Automatic Labels from Whisper" (2024)
- "LowCLIP: Adapting the CLIP Model Architecture for Low-Resource Languages in Multimodal Image Retrieval Task" (2024)

### Synthetic Data Generation
Papers exploring methods to create artificial training data:
- "Multimodal Neural Machine Translation for Low-resource Language Pairs using Synthetic Data" (2018)
- "Multimodal Neural Machine Translation for English to Hindi" (2021)
- "Low Resource Multimodal Neural Machine Translation of English-Hindi in News Domain" (2021)
- "Cross-Lingual Cross-Modal Retrieval with Noise-Robust Learning" (2022)
- "Mongolian to Chinese Multimodal Neural Machine Translation" (2022)
- "BITS-P at WAT 2023: Improving Indic Language Multimodal Translation by Image Augmentation using Diffusion Models" (2023)
- "CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages" (2023)
- "Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages" (2024)
- "ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams" (2024)
- "LaVy: Vietnamese Multimodal Large Language Model" (2024)
- "Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese" (2024)

### Architecture Innovations
Papers introducing novel model architectures and approaches:
- "Cycle Consistency" (2019)
- "Self-PT: Adaptive Self-Prompt Tuning for Low-Resource Visual Question Answering" (2023)
- "XtremeCLIP: Extremely Parameter-efficient Tuning for Low-resource Vision Language Understanding" (2023)
- "CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages" (2023)
- "MURAL: Multimodal, Multitask Retrieval Across Languages" (2021)

## Citation

TODO

## Contributing

We welcome contributions to this collection. Please submit a pull request with:
- The paper's PDF (if openly available)
- Updated BibTeX entry
- Brief description of the paper's key contributions
- Categorization according to our existing schema

## License

This collection is for research purposes only. All papers remain under their original licenses and copyright holders.

## Contact

For questions or suggestions about this collection, please open an issue in this repository.
